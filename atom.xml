<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王硕的博客</title>
  
  <subtitle>记录生活</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-03-06T07:44:29.478Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>王硕</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2021/03/06/AI-drone/"/>
    <id>http://example.com/2021/03/06/AI-drone/</id>
    <published>2021-03-06T07:39:32.843Z</published>
    <updated>2021-03-06T07:44:29.478Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="title-智能无人机"><a href="#title-智能无人机" class="headerlink" title="title:智能无人机"></a>title:智能无人机</h2><h1 id="实验报告"><a href="#实验报告" class="headerlink" title="实验报告"></a>实验报告</h1><p>王硕     2018202100</p><p>完整项目请参考：<a href="https://github.com/markinruc/ai20projects">https://github.com/markinruc/ai20projects</a></p><h1 id="2020-10-30"><a href="#2020-10-30" class="headerlink" title="2020.10.30"></a>2020.10.30</h1><h2 id="项目概论"><a href="#项目概论" class="headerlink" title="项目概论"></a>项目概论</h2><p>我们小组对于无人机项目的进度目前可大致分为三个阶段：<br></p><ol><li>使用Python程序完成对无人机的基本操控</li><li>结合语音识别技术</li><li>结合图像识别技术</li></ol><h2 id="阶段一-Python操纵无人机"><a href="#阶段一-Python操纵无人机" class="headerlink" title="阶段一  Python操纵无人机"></a>阶段一  Python操纵无人机</h2><p>我们最初的想法是使用Tello的原生接口实现对无人机的操纵，其中需要使用socket向无人机发送指令，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#连接tello</span></span><br><span class="line">tello_address = (<span class="string">&#x27;192.168.10.1&#x27;</span>, <span class="number">8889</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#本地计算机的Ip和端口</span></span><br><span class="line">local_address = (<span class="string">&#x27;&#x27;</span>, <span class="number">9000</span>)</span><br><span class="line"><span class="comment">#local_address = (&#x27;192.168.10.2&#x27;, 139)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个UDP连接用于发送命令</span></span><br><span class="line">sock = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绑定到本地地址和端口</span></span><br><span class="line">sock.bind(local_address)</span><br></pre></td></tr></table></figure><p>但是由于Windows系统与Tello系统的网络编程兼容性不好，因此这种连接不太稳定，且网络编程底层技术并不是本项目的重点，为了使这一部分变得简洁且有效，我们最终使用了tellopy这一Python的库，实现对无人机的高效操控，以下为tellopy的类与部分方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tello</span>(<span class="params">builtins.<span class="built_in">object</span></span>)</span></span><br><span class="line"><span class="class"> |  <span class="title">Tello</span>(<span class="params">port=<span class="number">9000</span></span>)</span></span><br><span class="line"><span class="class"> |</span></span><br><span class="line"><span class="class"> |  <span class="title">Methods</span> <span class="title">defined</span> <span class="title">here</span>:</span></span><br><span class="line"> |</span><br><span class="line"> |  __init__(self, port=<span class="number">9000</span>)</span><br><span class="line"> |      Initialize self.  See <span class="built_in">help</span>(<span class="built_in">type</span>(self)) <span class="keyword">for</span> accurate signature.</span><br><span class="line"> |</span><br><span class="line"> |  backward(self, val)</span><br><span class="line"> |      Backward tells the drone to go <span class="keyword">in</span> reverse. Pass <span class="keyword">in</span> an <span class="built_in">int</span> <span class="keyword">from</span> <span class="number">0</span>-<span class="number">100.</span></span><br><span class="line"> |</span><br><span class="line"> |  clockwise(self, val)</span><br><span class="line"> |      Clockwise tells the drone to rotate <span class="keyword">in</span> a clockwise direction.</span><br><span class="line"> |      Pass <span class="keyword">in</span> an <span class="built_in">int</span> <span class="keyword">from</span> <span class="number">0</span>-<span class="number">100.</span></span><br><span class="line"> |</span><br><span class="line"> |  connect(self)</span><br><span class="line"> |      Connect <span class="keyword">is</span> used to send the initial connection request to the drone.</span><br><span class="line"> |</span><br><span class="line"> |  counter_clockwise(self, val)</span><br><span class="line"> |      CounterClockwise tells the drone to rotate <span class="keyword">in</span> a counter-clockwise direction.</span><br><span class="line"> |      Pass <span class="keyword">in</span> an <span class="built_in">int</span> <span class="keyword">from</span> <span class="number">0</span>-<span class="number">100.</span></span><br><span class="line"> |</span><br><span class="line"> |  down(self, val)</span><br><span class="line"> |      Down tells the drone to descend. Pass <span class="keyword">in</span> an <span class="built_in">int</span> <span class="keyword">from</span> <span class="number">0</span>-<span class="number">100.</span></span><br><span class="line"> |</span><br><span class="line"> |  flip_back(self)</span><br><span class="line"> |      flip_back tells the drone to perform a backwards flip</span><br><span class="line"> |</span><br><span class="line"> |  flip_backleft(self)</span><br><span class="line"> |      flip_backleft tells the drone to perform a backwards left flip</span><br><span class="line"> |</span><br><span class="line"> |  flip_backright(self)</span><br><span class="line"> |      flip_backleft tells the drone to perform a backwards right flip</span><br><span class="line"> |</span><br><span class="line"> |  flip_forward(self)</span><br><span class="line"> .......</span><br></pre></td></tr></table></figure><h2 id="阶段二-无人机与语音识别的结合"><a href="#阶段二-无人机与语音识别的结合" class="headerlink" title="阶段二 无人机与语音识别的结合"></a>阶段二 无人机与语音识别的结合</h2><p>这一部分我们主要借助计算机接收到人发出的语音指令，经过Python实现的算法进行识别，然后将执行对应的无人机操纵函数实现对无人机的操控。<br><img src="extra/%E8%AF%AD%E9%9F%B3%E6%B5%8B%E8%AF%951.png" alt="avatar"><br><img src="extra/%E8%AF%AD%E9%9F%B3%E6%B5%8B%E8%AF%952.png" alt="avatar"><br>测试视频：</p><blockquote><p>链接：<a href="https://pan.baidu.com/s/1n9AiKVfvzHp84XZP-VlgWQ">https://pan.baidu.com/s/1n9AiKVfvzHp84XZP-VlgWQ</a><br>提取码：i7j0<br>复制这段内容后打开百度网盘手机App，操作更方便哦</p></blockquote><p>这一部分的代码路径为 <a href="src/scripts/face_recognition">src/scripts/face_recognition</a></p><h2 id="无人机与人脸识别的结合"><a href="#无人机与人脸识别的结合" class="headerlink" title="无人机与人脸识别的结合"></a>无人机与人脸识别的结合</h2><p>由于我们上个学期选修过多媒体技术课程，因此对图像识别有一定的了解。我们目前的设计是根据无人机传输到计算机上的视频流，识别出人脸，根据人脸的移动，调整无人机的旋转角度，实现无人机的镜头跟着人脸一起移动的效果。<br>测试视频：</p><blockquote><p>链接：<a href="https://pan.baidu.com/s/1n9AiKVfvzHp84XZP-VlgWQ">https://pan.baidu.com/s/1n9AiKVfvzHp84XZP-VlgWQ</a><br>提取码：i7j0<br>复制这段内容后打开百度网盘手机App，操作更方便哦</p></blockquote><p>这一部分的代码路径为：<a href="src/scripts/speech_recognition">src/scripts/speech_recognition</a></p><h2 id="下一阶段的目标"><a href="#下一阶段的目标" class="headerlink" title="下一阶段的目标"></a>下一阶段的目标</h2><ul><li>目前各个阶段的功能相对独立，没有融合到一起，希望接下来增加项目整体的整合性</li><li>利用我们实现的部分功能，结合现实生活解决一些问题</li></ul><h1 id="2020-11-20"><a href="#2020-11-20" class="headerlink" title="2020.11.20"></a>2020.11.20</h1><h2 id="阶段三"><a href="#阶段三" class="headerlink" title="阶段三"></a>阶段三</h2><h2 id="物体识别"><a href="#物体识别" class="headerlink" title="物体识别"></a>物体识别</h2><p>从10.30日之后，我们小组主要从语音和视觉两个方面开始探索，其中我主要负责视觉方面的物体检测，这一期间我主要尝试了tensorflow object detection 和 yolo两大物体识别框架，并尝试在本地运行的同时与无人机进行结合。</p><h4 id="tensorflow-object-detection"><a href="#tensorflow-object-detection" class="headerlink" title="tensorflow object detection"></a>tensorflow object detection</h4><p>框架链接：<a href="https://github.com/tensorflow/models/tree/master/research/object_detection">https://github.com/tensorflow/models/tree/master/research/object_detection</a><br>官网描述：</p><blockquote><p>Creating accurate machine learning models capable of localizing and identifying multiple objects in a single image remains a core challenge in computer vision. The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models. At Google we’ve certainly found this codebase to be useful for our computer vision needs, and we hope that you will as well.</p></blockquote><p>简言之，就是可以在同一张图片中检测并标注目标，而且对用户自己进行训练、应用十分友好。再历经千辛万苦，疯狂配置各种环境之后，我终于在本地成功搭建起来，并且导入了预训练模型，使用官方依据coco数据集训练得到的预权重，成功实现了目标检测。</p><p>测试图片：</p><img src="extra\tf1.png" alt="image-20201120204837319" style="zoom:67%;" /><p>为了更契合我们的项目，我们使用框架处理摄像头传输的视频，实现了即视的识别：</p><img src="extra\tf2.jpg" alt="978984fe212d13545d8e30a2bac2f1e" style="zoom:67%;" /><p>部分代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> image_path <span class="keyword">in</span> TEST_IMAGE_PATHS:</span><br><span class="line">  image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">  <span class="comment"># the array based representation of the image will be used later in order to prepare the</span></span><br><span class="line">  <span class="comment"># result image with boxes and labels on it.</span></span><br><span class="line">  image_np = load_image_into_numpy_array(image)</span><br><span class="line">  <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">  image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">  <span class="comment"># Actual detection.</span></span><br><span class="line">  output_dict = run_inference_for_single_image(image_np, detection_graph)</span><br><span class="line">  <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">  vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">      image_np,</span><br><span class="line">      output_dict[<span class="string">&#x27;detection_boxes&#x27;</span>],</span><br><span class="line">      output_dict[<span class="string">&#x27;detection_classes&#x27;</span>],</span><br><span class="line">      output_dict[<span class="string">&#x27;detection_scores&#x27;</span>],</span><br><span class="line">      category_index,</span><br><span class="line">      instance_masks=output_dict.get(<span class="string">&#x27;detection_masks&#x27;</span>),</span><br><span class="line">      use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">      line_thickness=<span class="number">8</span>)</span><br><span class="line">  plt.figure(figsize=IMAGE_SIZE)</span><br><span class="line">  plt.imshow(image_np)</span><br><span class="line">  plt.show()</span><br></pre></td></tr></table></figure><p>完整代码参考/src/scripts/object_detection/object_detection_tutorial.ipynb</p><h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><p>模型链接：<a href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a></p><p>yolo模型目前已经发展到了v5版本，我们分别尝试了v3、v4、v5三个版本，大约5、6个预训练模型，使用opencv作为图片处理工具，导入yolo的网络模型和与训练权重,其中v4版本的准确率较高，但是在我的电脑本地上处理速度较慢，大约0.7s处理一帧，目前不符合无人机即时检测的要求。v5版本准确率稍微逊色，但是效率比v4版本提高了十倍，已经符合了无人机的要求。</p><p>测试图片：</p><img src="\extra\yolo.png" alt="656c85d4b5d55089fd1fae986ee39c5" style="zoom: 50%;" /><h4 id="缺陷和方向"><a href="#缺陷和方向" class="headerlink" title="缺陷和方向"></a>缺陷和方向</h4><ul><li>目前所有的框架和模型都是通过CPU进行运算，效率较低，应用到摄像头上之后跳帧更为明显，特别是yolo-v4。下一步的解决方案是利用本地的英伟达1050Ti 的GPU进行运行，主要的难点在与配置显卡的驱动和cudnn加速，其实在这方面这周已经踩了不少的坑，但是最终仍然没有成功应用。下一阶段完成后，预计效率将会大大提升。</li><li>目前使用的模型为官方预训练模型，可以检测通用的物体 ，如人体、水杯等。我们目前已经开始使用labelimg工具标注自己的数据集进行训练，如我们自己的人脸、无人机的未来跟踪的小球等，以实现个性化的目标识别。</li><li>由于框架的环境配置过程复杂，不同的硬件设备、系统会有不同的方案和问题，所以本项目可移植性较差，需要先按照各个模型的官方文档配置环境。</li></ul><h2 id="手势识别"><a href="#手势识别" class="headerlink" title="手势识别"></a>手势识别</h2><p>我们j基于百度api初步实现了手势识别技术，测试时我们用自己电脑摄像头（连无人机摄像头同理）实时识别屏幕里出现的手势。目前可以识别1~9九个手势，可以将识别到的手势与无人机的动作联系起来。比如，我们可以指定手势“1”对应takeoff()动作。</p><p>手势识别代码放在：<a href="src/scripts/gesture_recongnize/gesture_recongnize.py">src/scripts/gesture_recongnize/gesture_recongnize.py</a></p><p>测试手势识别过程的一张图片如下（全部图片放在<a href="src/dataset/gesture_pictures">src/dataset/gesture_pictures</a>下）：</p><p><img src="F:/aaaa/AI/2018202100/extra/手势识别过程.png" alt="avatar"></p><p>手势识别效果如下：</p><p><img src="F:/aaaa/AI/2018202100/extra/手势识别结果.png" alt="avatar"></p><p>可以看到1~9九个手势都可以正常识别出来。</p><h2 id="无人机飞行路线规划"><a href="#无人机飞行路线规划" class="headerlink" title="无人机飞行路线规划"></a>无人机飞行路线规划</h2><p>为了让无人机可以按照我们规定的路径进行飞行，我们基于pygame的图形界面实现了一个控制无人机飞行的GUI。以一张中国人民大学的地图图片为例，我们可以在图片上点击要飞行的路径，路线规划函数会把它实际要飞行的路线保存到相应的JSON文件中，根据JSON文件中的数据来控制无人机要飞行的距离、旋转的角度等。</p><p>路线规划代码包括：（其中path_plan.py用来根据点击的路线生成JSON文件，tello_path_plan.py用来根据JSON文件控制无人机飞行）</p><p><a href="src/scripts/path_plan/path_plan.py">src/scripts/path_plan/path_plan.py</a></p><p><a href="src/scripts/path_plan/tello_path_plan.py">src/scripts/path_plan/tello_path_plan.py</a></p><p>路线规划的效果如下：</p><p>在GUi界面上点击如下路线（绕操场的路径）：</p><p><img src="F:/aaaa/AI/2018202100/extra/路线规划过程.png" alt="avatar"></p><p>然后会产生刚刚这个路径的信息，路径信息会保存到相应的JSON文件中<a href="src/scripts/path_plan/waypoints.json">src/scripts/path_plan/waypoints.json</a>：</p><p><img src="extra/%E8%B7%AF%E7%BA%BF%E8%A7%84%E5%88%92%E7%BB%93%E6%9E%9C.png" alt="avatar"></p><h2 id="期末汇总"><a href="#期末汇总" class="headerlink" title="期末汇总"></a>期末汇总</h2><h3 id="小组成果汇总"><a href="#小组成果汇总" class="headerlink" title="小组成果汇总"></a>小组成果汇总</h3><ul><li><p>人脸捕捉，追踪飞行</p><ul><li>训练四位小组成员的脸部图像数据，准确识别和跟踪飞行</li></ul></li><li><p>手势识别，手势控制</p><ul><li>通过图像识别手势，控制降落等操作</li></ul></li><li><p>语音控制，第二感官</p><ul><li>通过语音识别控制无人机的起飞和降落等操作</li></ul></li><li><p>自动避障系统</p><ul><li>以网球为例，通过图像识别，躲避网球</li></ul></li><li><p>双模式切换系统</p><ul><li>无人机识别到”switch”手势后，可以切换无人机飞行模式</li></ul></li></ul><h3 id="个人工作汇总"><a href="#个人工作汇总" class="headerlink" title="个人工作汇总"></a>个人工作汇总</h3><ul><li><p>研究无人机软硬件接口，探索Tellopy使用方法</p><ul><li>通过Python实现对无人机的控制，为后续复杂算法实现奠定基础</li></ul></li><li><p>探索无人机物体识别的相关算法和模型</p><ul><li><p>尝试使用了谷歌人脸识别API，百度手势识别API两种在线模型</p></li><li><p>使用了Tensorflow objects detection和YOLO两种物体识别框架，初步实现了无人机通过计算机视觉识别物体的效果。</p></li><li><p>标注小组成员的人脸和手势数据集，每张手势和人脸100张。将网球作为障碍物，同样也标注作为数据集(出于小组成员隐私考虑，不会上传数据集，望谅解)。</p><img src="extra\label_stop.png" style="zoom:67%;" /></li><li><p>基于我们自己标注的数据集，在YOLOv5的框架下训练我们自己的模型，最终达到了非常好的识别效果，识别准确率可以稳定在90%。可以达到以下效果：</p><img src="extra\障碍物识别效果.jpg" style="zoom: 50%;" /></li><li><p>根据无人机摄像头传输的视频流进行识别，编写人脸追踪、手势识别、躲避障碍物的算法。</p><ul><li>人脸追踪：人脸识别的算法可以得到一个当前人脸在视频框中的坐标，我们希望将人脸框始终动态稳定在视频框的中央，根据当前的人脸坐标和视频框中心点的坐标，可以计算出无人机需要移动的向量，通过Tellopy接口将移动指令传递给无人机。</li><li>手势识别：手势识别算法得到当前手势识别的种类，每一个手势种类会对应一个具体的无人机移动信号，条件判断后发出对应信号即可。</li><li>躲避障碍：与人脸追踪算法某种程度上互为逆操作，识别出障碍物的坐标后，需要计算出将障碍物移出当前视频框的需要做出的最小移动向量。</li></ul></li></ul></li></ul><h3 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h3><ul><li>前期准备。前期我们了解了很多的算法和模型，虽然其中大部分最终我们没有用到，看似浪费了时间，实际上开阔了视野，反而帮助我们在后期关键技术实现上面没有遇到太大的困难和错误。</li><li>动手能力。空谈模型和技术没有实际的意义，动手做出来才能算作结果。</li><li>团队协作。团队协作，扬长避短，我们小组四位成员，有些同学比较了解计算机视觉，有些同学比较擅长语言处理，各取所长，才能高效合作。</li><li>不要做无意义的功能的堆积，而是做一些有趣且有技术含量的东西。</li></ul><h3 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h3><blockquote><p>Python 3.7 及以上</p><p>Tensorflow 2.x</p></blockquote><h3 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h3><blockquote><ul><li>tellopy</li><li>pyaudio</li><li>aip</li><li>playsound</li><li>opencv</li><li>这只是部分包，可根据调试信息安装对应的Python包</li></ul></blockquote><h3 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h3><blockquote><p>若出现网络问题，请尝试以下方法</p><ul><li>使用Linux或MacOS</li><li>使用有线网络连接以便于WiFi连接无人机</li><li>若人脸识别出现问题，请关注代码中的路径问题，并不是所有IDE都能智能处理路径问题</li><li>tensorflow和yolo的环境配置请参考官方文档</li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;title-智能无人机&quot;&gt;&lt;a href=&quot;#title-智能无人机&quot; class=&quot;headerlink&quot; title=&quot;title:智能无人机&quot;&gt;&lt;/a&gt;title:智能无人机&lt;/h2&gt;&lt;h1 id=&quot;实验报告&quot;&gt;&lt;a href=&quot;#实验报告&quot; cl</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello blog</title>
    <link href="http://example.com/2021/01/31/hello-world/"/>
    <id>http://example.com/2021/01/31/hello-world/</id>
    <published>2021-01-31T06:10:10.442Z</published>
    <updated>2021-02-01T01:51:17.533Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to my blog. I started this blog on January 31, 2021 to record life and encourage learning.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to my blog. I started this blog on January 31, 2021 to record life and encourage learning.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Qui</summary>
      
    
    
    
    
  </entry>
  
</feed>
